{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TD3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68f5f6f042d43b51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff9d7dc7ed45a9b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CriticNet(torch.nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super(CriticNet, self).__init__()\n",
    "        # critic1\n",
    "        self.fc1 = torch.nn.Linear(env.observation_space.shape[0] + env.action_space.shape[0], 128)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(128, 128)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(128, env.action_space.shape[0])\n",
    "\n",
    "        # critic2\n",
    "        self.fc4 = torch.nn.Linear(env.observation_space.shape[0] + env.action_space.shape[0], 128)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.fc5 = torch.nn.Linear(128, 128)\n",
    "        self.relu5 = torch.nn.ReLU()\n",
    "        self.fc6 = torch.nn.Linear(128, env.action_space.shape[0])\n",
    "\n",
    "    def forward(self, observation, action):\n",
    "        cat_x = torch.cat([observation, action], dim=1)\n",
    "\n",
    "        # critic1\n",
    "        x1 = self.relu1(self.fc1(cat_x))\n",
    "        x1 = self.relu2(self.fc2(x1))\n",
    "        x1 = self.fc3(x1)\n",
    "\n",
    "        # critic2\n",
    "        x2 = self.relu4(self.fc4(cat_x))\n",
    "        x2 = self.relu5(self.fc5(x2))\n",
    "        x2 = self.fc6(x2)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "    def Q1(self, observation, action):\n",
    "        cat_x = torch.cat([observation, action], dim=1)\n",
    "\n",
    "        # critic1\n",
    "        x1 = self.relu1(self.fc1(cat_x))\n",
    "        x1 = self.relu2(self.fc2(x1))\n",
    "        x1 = self.fc3(x1)\n",
    "\n",
    "        return x1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "137104b826319789"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ActorNet(torch.nn.Module):\n",
    "    def __init__(self, env, max_action):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(env.observation_space.shape[0], 128)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(128, 128)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(128, env.action_space.shape[0])\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))\n",
    "        x = self.max_action * x\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "510c3a5c5c3d006f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TD3:\n",
    "    def __init__(self, env, batch_size=256):\n",
    "        self.critic = CriticNet(env)\n",
    "        self.critic_target = copy.deepcopy(self.critic)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=1e-4)\n",
    "\n",
    "        self.actor = ActorNet(env, max_action=env.action_space.high[0])\n",
    "        self.actor_target = copy.deepcopy(self.actor)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=1e-4)\n",
    "\n",
    "        self.max_action = env.action_space.high[0]\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.buffer = deque(maxlen=(10 ** 6))\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = 0.99\n",
    "        self.tau = 0.005\n",
    "        self.noise_clip = 0.5 * self.max_action\n",
    "        self.policy_noise = 0.2 * self.max_action\n",
    "        self.iter = 0\n",
    "        self.policy_freq = 2\n",
    "        self.env = env\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            action = self.actor(state).squeeze(0).numpy()\n",
    "        return action\n",
    "\n",
    "    def update_target(self):\n",
    "\n",
    "        for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "        for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "    def learn(self):\n",
    "        self.iter += 1\n",
    "        batch_samples = random.sample(self.buffer, self.batch_size)\n",
    "        state_lst, action_lst, reward_lst, new_state_lst, done_lst = zip(*batch_samples)\n",
    "        state_lst = torch.FloatTensor(state_lst)\n",
    "        action_lst = torch.FloatTensor(action_lst)\n",
    "        reward_lst = torch.FloatTensor(reward_lst)\n",
    "        new_state_lst = torch.FloatTensor(new_state_lst)\n",
    "        done_lst = torch.FloatTensor(done_lst)\n",
    "\n",
    "        # 更新critic网络\n",
    "        with torch.no_grad():\n",
    "            noise = torch.clip(torch.randn_like(action_lst) * self.policy_noise, -self.noise_clip, self.noise_clip)\n",
    "            new_action = torch.clip(self.actor_target(new_state_lst) + noise, -self.max_action, self.max_action)\n",
    "\n",
    "        q_target1, q_target2 = self.critic_target(new_state_lst, new_action)\n",
    "        q_target = reward_lst + self.gamma * (torch.min(q_target1, q_target2)) * (1 - done_lst)\n",
    "        q_value1, q_value2 = self.critic(state_lst, action_lst)\n",
    "        td_error = self.mse(q_target, q_value1) + self.mse(q_target, q_value2)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        td_error.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # 更新actor网络\n",
    "        if self.iter % self.policy_freq == 0:\n",
    "            action = self.actor(state_lst)\n",
    "            q_value1 = self.critic.Q1(state_lst, action)\n",
    "            loss_actor = -torch.mean(q_value1)\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            loss_actor.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.update_target()\n",
    "\n",
    "    def model_save(self, epoch, model_folder='./model_save', max_models=5):\n",
    "        if not os.path.exists(model_folder):\n",
    "            os.makedirs(model_folder)\n",
    "        buffer_memery_path = os.path.join(model_folder, 'buffer.pkl')\n",
    "        model_path = os.path.join(model_folder, f'epoch_{epoch}.pth')\n",
    "        with open(buffer_memery_path, 'wb') as file:\n",
    "            pickle.dump(self.buffer, file)\n",
    "        torch.save({\n",
    "            'actor_model_state_dict': self.actor.state_dict(),\n",
    "            'actor_target_model_state_dict': self.actor_target.state_dict(),\n",
    "            'critic_model_state_dict': self.critic.state_dict(),\n",
    "            'critic_target_model_state_dict': self.critic_target.state_dict(),\n",
    "            'actor_optimizer_state_dict': self.actor_optimizer.state_dict(),\n",
    "            'critic_optimizer_state_dict': self.critic_optimizer.state_dict()\n",
    "        }, model_path)\n",
    "        model_files = [f for f in os.listdir(model_folder) if f.startswith('epoch_') and f.endswith('.pth')]\n",
    "        model_files = sorted(model_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "        while len(model_files) > max_models:\n",
    "            old_model_path = os.path.join(model_folder, model_files[0])\n",
    "            os.remove(old_model_path)\n",
    "            model_files.pop(0)\n",
    "\n",
    "    def model_load(self, model_path, buffer_path):\n",
    "        with open(buffer_path, 'rb') as file:\n",
    "            self.buffer = pickle.load(file)\n",
    "\n",
    "        checkpoint = torch.load(model_path)\n",
    "        self.actor.load_state_dict(checkpoint['actor_model_state_dict'])\n",
    "        self.actor_target.load_state_dict(checkpoint['actor_target_model_state_dict'])\n",
    "        self.critic.load_state_dict(checkpoint['critic_model_state_dict'])\n",
    "        self.critic_target.load_state_dict(checkpoint['critic_target_model_state_dict'])\n",
    "        self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer_state_dict'])\n",
    "        self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer_state_dict'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d3e0d34c8f77f2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalkerHardcore-v3\", render_mode='human')\n",
    "td3 = TD3(env, 256)\n",
    "td3.model_load(\"./model_save/epoch_4990.pth\",\"./model_save/buffer.pkl\")\n",
    "episode_rewards = 0\n",
    "for _ in range(50):\n",
    "    start_time = time.time()\n",
    "    state, _ = env.reset()\n",
    "    step = 0\n",
    "    while True:\n",
    "        a = td3.choose_action(torch.tensor(state))\n",
    "        new_state, reward, done, _, _ = env.step(a)\n",
    "        step += 1\n",
    "        state = new_state\n",
    "        if done:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time)\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a8505b2d8e772f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4467a7db8e39694"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
